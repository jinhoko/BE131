{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Notebook\n",
    "\n",
    "    Course: BioE 131\n",
    "    Lab No: Lab #7\n",
    "    Submission date: \n",
    "    \n",
    "    Team members: Michael Fernandez, Jinho Ko\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104857600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def b_generator(s, p):\n",
    "    data = np.random.choice( [0,1], size = s, replace = True, p = [p, 1.0-p])\n",
    "    data = np.packbits(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "def DNA_generator(s):\n",
    "    data = np.random.choice( ['A', 'T', 'C', 'G'], size = s, replace = True, p = [ 1.0/4.0 for _ in range(4) ] )\n",
    "    #data = np.packbits(data)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def Protein_generator(s):\n",
    "    data = np.random.choice( list('ARNDCEQGHILKMFPSTWYV'), size = s, replace = True, p = [1.0/20.0 for _ in range(20)] )\n",
    "    #data = np.packbits(data)\n",
    "\n",
    "    return data\n",
    "    \n",
    "open('zeros_100p', 'wb').write( b_generator( 8* 100 * 2**20 , 1.0))\n",
    "open('zeros_90p', 'wb').write( b_generator(8* 100 * 2**20, 0.9))\n",
    "open('zeros_80p', 'wb').write( b_generator(8* 100 * 2**20, 0.8))\n",
    "open('zeros_70p', 'wb').write( b_generator(8* 100 * 2**20, 0.7))\n",
    "open('zeros_60p', 'wb').write( b_generator(8* 100 * 2**20, 0.6))\n",
    "open('zeros_50p', 'wb').write( b_generator(8* 100 * 2**20, 0.5))\n",
    "\n",
    "open('nt_seq.fa', 'w').write( ''.join(DNA_generator(10**6) ) ) \n",
    "open('aa_seq.fa', 'w').write( ''.join(Protein_generator(10**6)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memo of Compression Time, Rate\n",
    "\n",
    "Zeros_100p :  Input size : 105MB \n",
    "- gzip : real 0.686 user 0.656, sys 0.028 | 102kb\n",
    "- bzip2 :real 1.001s user 0.940  sys 0.060 | 112B\n",
    "- pbzip2 : real 0.103 user 1.836, sys 0.092 | 6.52 kb\n",
    "- ArithmeticCompress : 15.115 12.054 0.052 | 1.03 kb\n",
    "\n",
    "Zeros_90p :  Input size : 105MB\n",
    "- gzip :real 19.292 user 19.287 sys 0.1 | 58.7 MB\n",
    "- bzip2 :real 11.708 user 11.595. sys 0.112 | 61.2MB\n",
    "- pbzip2 : real .767 user 18.935. sys 0.678 | 61.2 MB\n",
    "- ArithmeticCompress :real 28.687 user 28.569, 0.128 | 49.2 MB\n",
    "\n",
    "Zeros_80p :  Input size : 105MB\n",
    "- gzip :real 16.043 user 15.859 sys 0.148 | 81.2MB\n",
    "- bzpi2 :real 12.742 user 12.637 sys 0.104 | 86.6MB\n",
    "- pbzip2 :real 0.945  23.834, 0.865 | 86.7MB\n",
    "- ArithmeticCompress :real 11.991, 11.875, 0.116 | 65.8MB\n",
    "\n",
    "Zeros_70p :  Input size : 105MB\n",
    "- gzip :real 6.066. 5.929. 0.132 | 93.6MB\n",
    "- bzpi2 :real 14.83 14.664, 0.153 | 99.8MB\n",
    "- pbzip2 :real 1.194 29.801 0.746 | 99.8MB\n",
    "- ArithmeticCompress :real 39.193 39.018 0.160 | 92.4MB\n",
    "\n",
    "Zeros_60p :  Input size : 105MB\n",
    "- gzip :  real    0m4.333s  102mb\n",
    "user    0m4.124s   \n",
    "sys     0m0.208s   \n",
    "- bzip2 :  real    0m15.934s  105mb\n",
    "user    0m15.777s\n",
    "sys     0m0.157s\n",
    "- pbzip2 :  real    0m1.412s  105mb\n",
    "user    0m36.861s\n",
    "sys     0m0.923s\n",
    "- ArithmeticCompress : real    0m43.946s  102mb\n",
    "user    0m43.804s\n",
    "sys     0m0.129s\n",
    "\n",
    "Zeros_50p :  Input size : 105MB\n",
    "- gzip : real    0m3.550s  105mb\n",
    "user    0m3.442s\n",
    "sys     0m0.108s\n",
    "- bzip2 :real    0m17.856s  105mb\n",
    "user    0m17.711s\n",
    "sys     0m0.144s\n",
    "- pbzip2 :real 0m1.512s  105mb\n",
    "user    0m39.113s\n",
    "sys     0m0.890s\n",
    "- ArithmeticCompress :real 0m42.529s  105mb\n",
    "user    0m42.367s\n",
    "sys     0m0.160s\n",
    "\n",
    "nt_seq.fa :  Input size : 1MB\n",
    "- gzip : real 0m0.126s | 293kb\n",
    "user    0m0.121s\n",
    "sys     0m0.004s\n",
    "- bzip2 :real 0m0.105s | 274kb\n",
    "user    0m0.101s\n",
    "sys     0m0.004s\n",
    "- pbzip2 :real 0m0.126s | 274kb\n",
    "user    0m0.137s\n",
    "sys     0m0.005s\n",
    "- ArithmeticCompress :real 0m0.251s | 251kb\n",
    "user    0m0.251s\n",
    "sys     0m0.000s\n",
    "\n",
    "aa_seq.fa :  Input size : 1MB\n",
    "- gzip :real 0m0.051s | 606kb\n",
    "user    0m0.050s\n",
    "sys     0m0.000s\n",
    "- bzip2 :real 0m0.132s | 553kb\n",
    "user    0m0.124s\n",
    "sys     0m0.008s\n",
    "- pbzip2 :real 0m0.132s | 553kb\n",
    "user    0m0.138s\n",
    "sys     0m0.009s\n",
    "- ArithmeticCompress:real  0m0.288s | 541kb\n",
    "user    0m0.288s\n",
    "sys     0m0.000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| % compression      | 100   | 90   | 80   | 70   | 60  | 50 | nt   | aa   |\n",
    "|--------|-------|------|------|------|-----|----|------|------|\n",
    "| gzip   | 99.9  | 44.1 | 22.7 | 10.8 | 2.8 | 0  | 70.7 | 39.4 |\n",
    "| bzip2  | 100.0 | 41.7 | 17.5 | 5.0  | 0   | 0  | 72.6 | 44.7 |\n",
    "| pbzip2 | 99.9  | 41.7 | 17.4 | 5.0  | 0   | 0  | 72.6 | 44.7 |\n",
    "| AC     | 99.9  | 53.1 | 37.3 | 12.0 | 2.8 | 0  | 74.9 | 71.2 |\n",
    "\n",
    "| time   | 100    | 90     | 80     | 70     | 60     | 50     | nt   | aa   |\n",
    "|--------|--------|--------|--------|--------|--------|--------|------|------|\n",
    "| gzip   | .486   | 19.292 | 16.043 | 6.066  | 4.333  | 3.550  | .126 | .051 |\n",
    "| bzip2  | 1.001  | 11.708 | 12.742 | 14.83  | 15.934 | 17.856 | .105 | .132 |\n",
    "| pbzip2 | .103   | 0.767  | 0.945  | 1.194  | 1.412  | 1.512  | .126 | .132 |\n",
    "| AC     | 15.115 | 28.687 | 11.991 | 39.193 | 43.946 | 42.529 | .251 | .288 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "#### Which algorithm achieves the best level of compression on each file type?\n",
    "- for zeros_100p, bzip2 was the best, and in other files (7) , ArithmeticCompress was dominant.\n",
    "\n",
    "#### Which algorithm is the fastest?\n",
    "- for nt, bzip2 was the best, and in other 7 files, pbzip2 was dominant.\n",
    "\n",
    "#### What is the difference between bzip2 and pbzip2? Do you expect one to be faster and why?\n",
    "- pbzip2 should be faster because it supports parallel computing in multi-core CPU. Therefore, the time difference shown in our result means that our server is operated with multi-core CPU.\n",
    "\n",
    "#### How does the level of compression change as the percentage of zeros increases? Why does this happen?\n",
    "- As the precentages of zeros goes down(100->50) , the % compression decreases, because the algorithm works more effectively when there are more repetitive sequences. Therefore when there are 50% zeros, there are less repetitive sequences compared to 90 or 100.\n",
    "\n",
    "#### What is the minimum number of bits required to store a single DNA base?\n",
    "- by Shannon's theory of information, the bits required = log2(4) = 2 bits.\n",
    "\n",
    "#### What is the minimum number of bits required to store an amino acid letter?\n",
    "- by Shannon's theory of information, the bits required = log2(20) = 4.32 -> 5 bits. \n",
    "\n",
    "#### In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and protein sequences?\n",
    "- theoretically, DNA sequence should be 2500kb and Protein sequence should be 6250kb.\n",
    "- But in reality, DNA gzip/bzip2 required 293kb, 274kb, and Protein gzip/zip2 required 606kb, 553kb\n",
    "\n",
    "\n",
    "#### Are gzip and bzip2 performing well on DNA and proteins?\n",
    "- for DNA, around 70% was compressed, and for Protein around 40% was compressed. So we guess the algoritms work well on DNA and proteins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing Real Data\n",
    "\n",
    "From your knowledge about querying biological databases, find the nucleic acid sequences of gp120 homologs from at least 10 different HIV isolates and concatenate them together into a single multi-FASTA.\n",
    "\n",
    "A priori, do you expect to achieve better or worse compression here than random data? Why?  \n",
    "- We guess the compression would work better because in real DNA sequences, there are often many repetitive sequences than randomized sequencees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| % compression   | nt   | GP120_10 |\n",
    "|--------|------|----------|\n",
    "| gzip   | 70.7 | 75.4     |\n",
    "| bzip2  | 72.6 | 78.2     |\n",
    "| pbzip2 | 72.6 | 78.2     |\n",
    "| AC     | 74.9 | 72.8     |\n",
    "\n",
    "| time   | nt   | GP120_10 |\n",
    "|--------|------|----------|\n",
    "| gzip   | .126 | .022     |\n",
    "| bzip2  | .105 | .020     |\n",
    "| pbzip2 | .126 | .018     |\n",
    "| AC     | .251 | .035     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the compression ratio of this file compare to random data?  \n",
    "- lt looks like compression ratio for gzip, bzip, pbzip is better in gp120 homolgs fasta file than random nt datas. For Arithmetic Compression, random sequences were better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating compression of 1000 terabytes  \n",
    "\n",
    "Most of the data, say 80%, is re-sequencing of genomes and plasmids that are very similar to each other.  \n",
    "Another 10% might be protein sequences,  \n",
    "and the last 10% are binary microscope images  \n",
    "\n",
    "which weâ€™ll assume follow the worst-case scenario of being completely random.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which algorithm do you propose to use for each type of data? \n",
    "- For genomes and plasmids, we suggest pbzip2, because it's more faster and efficient(78.2%) compared to AC or gzip or bzip(in parallel computing environment)\n",
    "- For protein sequences, we would suggest ArithmeticCompress, which compressed about 71.2% (double compression rate compared to other algorithms)in our experiment.\n",
    "- For binary microscope images, we won't suggest any compression, because compression won't work in given situation (worst 50/50& of 0/1s). Instead, we can devote the memory to other progress.\n",
    "\n",
    "Provide an estimate for the fraction of space you can save using your compression scheme.  \n",
    "- for 800TB (of genomes and plasmids) : 78.2 % compressed\n",
    "- for 100TB (of protein seqs) : 71.2 % compressed\n",
    "- for 100TB (of binary image) : 0 % compressed\n",
    "\n",
    "-> totally, 174.4 + 28.8 + 0 = 203.2 TB / 1000TB (79.68% compressed)\n",
    "\n",
    "How much of a bonus do you anticipate receiving this year?  \n",
    "- *50 dollars for 1TB is given as bonus.\n",
    "- 50 dollars * 796.8 TB = 39,840 dollars are saved every day.\n",
    "- Therefore, annual bonus the team gets is, 39,840*365 = 14,541,600 Dollars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
